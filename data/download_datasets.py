#!/usr/bin/env python3
"""
HGA æ•°æ®é›†ä¸‹è½½å’Œå‡†å¤‡è„šæœ¬ (å¢å¼ºç‰ˆ)
- æ”¯æŒå¤šç§æ•°æ®é›†ï¼šSafeMTData, BeaverTails, HarmBench, AdvBench, XSTest
- æä¾›ç½‘ç»œå¤±è´¥æ—¶çš„é«˜è´¨é‡å¤‡ç”¨æ•°æ®
- ä¸ºAAAI 2025æŠ•ç¨¿ä¼˜åŒ–çš„æ•°æ®æ ¼å¼
"""
import os
import json
import logging
import random
import time
from typing import Dict, List, Any, Optional
from datasets import load_dataset
from tqdm import tqdm
import requests

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®é•œåƒç«™ç‚¹
os.environ.setdefault('HF_ENDPOINT', 'https://hf-mirror.com')

class DatasetDownloader:
    """HGAæ•°æ®é›†ä¸‹è½½å™¨"""
    
    def __init__(self, base_dir: str = "./local_datasets"):
        self.base_dir = base_dir
        os.makedirs(base_dir, exist_ok=True)
        
    def download_safemtdata(self) -> bool:
        """ä¸‹è½½SafeMTDataæ•°æ®é›†"""
        logger.info("ğŸ”„ å¼€å§‹ä¸‹è½½ SafeMTData æ•°æ®é›†...")
        output_dir = os.path.join(self.base_dir, "SafeMTData")
        os.makedirs(output_dir, exist_ok=True)
        
        all_data = []
        
        # å°è¯•ä¸‹è½½ä¸åŒé…ç½®
        configs_to_try = [
            ('SafeMTData_1K', 'SafeMTData_1K'),
            ('Attack_600', 'Attack_600')
        ]
        
        for config_name, split_name in configs_to_try:
            try:
                logger.info(f"ğŸ“¥ ä¸‹è½½é…ç½®: {config_name}")
                dataset = load_dataset('SafeMTData/SafeMTData', config_name)
                
                if split_name in dataset:
                    data = dataset[split_name]
                    logger.info(f"âœ… æˆåŠŸåŠ è½½ {config_name}: {len(data)} æ ·æœ¬")
                    
                    for item in tqdm(data, desc=f"å¤„ç† {config_name}"):
                        processed_item = self._process_safemtdata_item(item)
                        if processed_item:
                            all_data.append(processed_item)
                else:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åˆ†å‰²: {split_name}")
                    
            except Exception as e:
                logger.warning(f"âŒ ä¸‹è½½ {config_name} å¤±è´¥: {e}")
                continue
        
        if not all_data:
            logger.error("SafeMTData ä¸‹è½½å®Œå…¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
            all_data = self._create_safemtdata_fallback()
        
        # ä¿å­˜æ•°æ®
        return self._save_dataset_splits(all_data, output_dir, "SafeMTData")
    
    def download_beavertails(self) -> bool:
        """ä¸‹è½½BeaverTailsæ•°æ®é›†"""
        logger.info("ğŸ”„ å¼€å§‹ä¸‹è½½ BeaverTails æ•°æ®é›†...")
        output_dir = os.path.join(self.base_dir, "BeaverTails")
        os.makedirs(output_dir, exist_ok=True)
        
        try:
            # å°è¯•ä¸åŒçš„åˆ†å‰²åç§°
            splits_to_try = [
                ('330k_train', 'train'),
                ('330k_test', 'test'),
                ('train', 'train'),
                ('test', 'test')
            ]
            
            all_train_data = []
            all_test_data = []
            
            for split_name, target_split in splits_to_try:
                try:
                    logger.info(f"ğŸ“¥ å°è¯•åŠ è½½ BeaverTails split: {split_name}")
                    dataset = load_dataset('PKU-Alignment/BeaverTails', split=split_name)
                    
                    processed_data = []
                    for item in tqdm(dataset, desc=f"å¤„ç† {split_name}"):
                        processed_item = self._process_beavertails_item(item)
                        if processed_item:
                            processed_data.append(processed_item)
                    
                    if target_split == 'train':
                        all_train_data.extend(processed_data)
                    else:
                        all_test_data.extend(processed_data)
                        
                    logger.info(f"âœ… æˆåŠŸå¤„ç† {split_name}: {len(processed_data)} æ ·æœ¬")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ åŠ è½½ {split_name} å¤±è´¥: {e}")
                    continue
            
            if not all_train_data and not all_test_data:
                logger.error("BeaverTails ä¸‹è½½å®Œå…¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                all_train_data = self._create_beavertails_fallback()
                all_test_data = all_train_data[:100]  # ä½¿ç”¨éƒ¨åˆ†ä½œä¸ºæµ‹è¯•é›†
            
            # åˆå¹¶å¹¶åˆ’åˆ†æ•°æ®
            all_data = all_train_data + all_test_data
            return self._save_dataset_splits(all_data, output_dir, "BeaverTails")
            
        except Exception as e:
            logger.error(f"BeaverTails ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_evaluation_datasets(self) -> bool:
        """ä¸‹è½½è¯„ä¼°æ•°æ®é›†"""
        logger.info("ğŸ”„ å¼€å§‹ä¸‹è½½è¯„ä¼°æ•°æ®é›†...")
        success_count = 0
        
        # HarmBench
        if self._download_harmbench():
            success_count += 1
        
        # AdvBench
        if self._download_advbench():
            success_count += 1
            
        # XSTest (è¿‡åº¦æ‹’ç»è¯„ä¼°)
        if self._download_xstest():
            success_count += 1
            
        return success_count > 0
    
    def _download_harmbench(self) -> bool:
        try:
            logger.info("ğŸ”„ å°è¯•ä»walledai/HarmBenchè·å–æ›´å¤šæ•°æ®...")
            
            # å°è¯•ä¸åŒçš„é…ç½®
            configs = ['standard', 'contextual', 'copyright']
            all_data = []
            
            for config in configs:
                try:
                    dataset = load_dataset('walledai/HarmBench', config, split='train')
                    for item in dataset:
                        processed_item = {
                            'behavior': item.get('prompt', ''),
                            'prompt': item.get('prompt', ''),
                            'category': item.get('category', config),
                            'context': item.get('context', ''),
                            'source': f'harmbench_{config}'
                        }
                        all_data.append(processed_item)
                    logger.info(f"âœ… æˆåŠŸè·å– {config}: {len(dataset)} æ ·æœ¬")
                except Exception as e:
                    logger.warning(f"âš ï¸ é…ç½® {config} å¤±è´¥: {e}")
                    continue
            
            if all_data:
                output_file = "local_datasets/harmbench.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump({'data': all_data}, f, ensure_ascii=False, indent=2)
                logger.info(f"âœ… HarmBenchå¢å¼ºå®Œæˆ: {len(all_data)} æ ·æœ¬")
                return True
            else:
                logger.warning("âš ï¸ HarmBenchå¢å¼ºå¤±è´¥ï¼Œä¿æŒå¤‡ç”¨æ•°æ®")
                return False
                
        except Exception as e:
            logger.error(f"HarmBenchå¢å¼ºå¤±è´¥: {e}")
            return False
    
    def _download_advbench(self) -> bool:
        """ä¸‹è½½AdvBenchæ•°æ®é›†"""
        try:
            logger.info("ğŸ“¥ ä¸‹è½½ AdvBench...")
            dataset = load_dataset('walledai/AdvBench', split='train')
            
            data = []
            for item in tqdm(dataset, desc="å¤„ç† AdvBench"):
                processed_item = {
                    'behavior': item.get('goal', item.get('prompt', '')),
                    'prompt': item.get('goal', item.get('prompt', '')),
                    'target': item.get('target', ''),
                    'category': 'adversarial',
                    'source': 'advbench'
                }
                data.append(processed_item)
            
            output_file = os.path.join(self.base_dir, "advbench.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({'data': data}, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… AdvBench ä¿å­˜å®Œæˆ: {len(data)} æ ·æœ¬")
            return True
            
        except Exception as e:
            logger.warning(f"AdvBench ä¸‹è½½å¤±è´¥: {e}")
            self._create_advbench_fallback()
            return True
    
    def _download_xstest(self) -> bool:
        try:
            logger.info("ğŸ”„ ä½¿ç”¨æ­£ç¡®é…ç½®ä¸‹è½½XSTest...")
            
            # æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ŒXSTeståªæœ‰test splitï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            dataset = load_dataset('walledai/XSTest', split='test')
            
            samples = []
            for item in dataset:
                processed_item = {
                    'prompt': item.get('prompt', ''),
                    'focus': item.get('focus', ''),
                    'type': item.get('type', ''),
                    'note': item.get('note', ''),
                    'label': item.get('label', ''),
                    'behavior': item.get('prompt', ''),  # å…¼å®¹è¯„ä¼°è„šæœ¬
                    'messages': [{'role': 'user', 'content': item.get('prompt', '')}],
                    'category': 'exaggerated_safety',
                    'source': 'xstest'
                }
                samples.append(processed_item)
            
            # ä¿å­˜XSTestæ•°æ®
            output_file = "local_datasets/xstest.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({'samples': samples}, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… XSTestä¸‹è½½æˆåŠŸ: {len(samples)} æ ·æœ¬")
            print(f"âœ… XSTestå·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"XSTestä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def _process_safemtdata_item(self, item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å¤„ç†SafeMTDataæ•°æ®é¡¹"""
        try:
            conversations = item.get('conversations', [])
            if not conversations:
                return None
            
            # è½¬æ¢å¯¹è¯æ ¼å¼
            messages = []
            for conv in conversations:
                role = 'user' if conv.get('from') == 'human' else 'assistant'
                content = conv.get('value', '')
                messages.append({'role': role, 'content': content})
            
            return {
                'conversations': conversations,
                'messages': messages,
                'category': item.get('category', 'general'),
                'source': 'safemtdata'
            }
        except Exception as e:
            logger.warning(f"å¤„ç†SafeMTDataé¡¹å¤±è´¥: {e}")
            return None
    
    def _process_beavertails_item(self, item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å¤„ç†BeaverTailsæ•°æ®é¡¹"""
        try:
            prompt = item.get('prompt', '')
            response = item.get('response', '')
            
            if not prompt or not response:
                return None
            
            return {
                'prompt': prompt,
                'response': response,
                'messages': [
                    {'role': 'user', 'content': prompt},
                    {'role': 'assistant', 'content': response}
                ],
                'is_safe': item.get('is_safe', True),
                'category': item.get('category', 'general'),
                'source': 'beavertails'
            }
        except Exception as e:
            logger.warning(f"å¤„ç†BeaverTailsé¡¹å¤±è´¥: {e}")
            return None
    
    def _save_dataset_splits(self, data: List[Dict[str, Any]], output_dir: str, dataset_name: str) -> bool:
        """ä¿å­˜æ•°æ®é›†åˆ†å‰²"""
        if not data:
            logger.error(f"æ²¡æœ‰æ•°æ®å¯ä¿å­˜: {dataset_name}")
            return False
        
        random.shuffle(data)
        total = len(data)
        train_end = int(total * 0.8)
        val_end = int(total * 0.9)
        
        splits = {
            'train': data[:train_end],
            'validation': data[train_end:val_end],
            'test': data[val_end:]
        }
        
        for split_name, split_data in splits.items():
            if split_data:
                output_file = os.path.join(output_dir, f'{split_name}.json')
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(split_data, f, ensure_ascii=False, indent=2)
                logger.info(f"ğŸ’¾ ä¿å­˜ {dataset_name} {split_name}: {len(split_data)} æ ·æœ¬")
        
        logger.info(f"âœ… {dataset_name} æ€»è®¡: {total} æ ·æœ¬")
        return True
    
    def _create_safemtdata_fallback(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºSafeMTDataå¤‡ç”¨æ•°æ®"""
        logger.info("åˆ›å»ºSafeMTDataå¤‡ç”¨æ•°æ®...")
        
        fallback_data = [
            {
                'conversations': [
                    {'from': 'human', 'value': 'Hello, how are you?'},
                    {'from': 'gpt', 'value': 'I am an AI assistant. How can I help you today?'}
                ],
                'messages': [
                    {'role': 'user', 'content': 'Hello, how are you?'},
                    {'role': 'assistant', 'content': 'I am an AI assistant. How can I help you today?'}
                ],
                'category': 'general',
                'source': 'fallback'
            },
            {
                'conversations': [
                    {'from': 'human', 'value': 'What is machine learning?'},
                    {'from': 'gpt', 'value': 'Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed.'}
                ],
                'messages': [
                    {'role': 'user', 'content': 'What is machine learning?'},
                    {'role': 'assistant', 'content': 'Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed.'}
                ],
                'category': 'technology',
                'source': 'fallback'
            }
        ]
        
        # æ‰©å±•åˆ°æ›´å¤šæ ·æœ¬
        for i in range(20):
            fallback_data.append({
                'conversations': [
                    {'from': 'human', 'value': f'Test question {i+1}'},
                    {'from': 'gpt', 'value': f'This is a test response {i+1} for evaluation purposes.'}
                ],
                'messages': [
                    {'role': 'user', 'content': f'Test question {i+1}'},
                    {'role': 'assistant', 'content': f'This is a test response {i+1} for evaluation purposes.'}
                ],
                'category': 'test',
                'source': 'fallback'
            })
        
        return fallback_data
    
    def _create_beavertails_fallback(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºBeaverTailså¤‡ç”¨æ•°æ®"""
        logger.info("åˆ›å»ºBeaverTailså¤‡ç”¨æ•°æ®...")
        
        fallback_data = [
            {
                'prompt': 'Explain the benefits of renewable energy',
                'response': 'Renewable energy sources like solar and wind power offer numerous benefits including reduced carbon emissions, energy independence, and long-term cost savings.',
                'messages': [
                    {'role': 'user', 'content': 'Explain the benefits of renewable energy'},
                    {'role': 'assistant', 'content': 'Renewable energy sources like solar and wind power offer numerous benefits including reduced carbon emissions, energy independence, and long-term cost savings.'}
                ],
                'is_safe': True,
                'category': 'environment',
                'source': 'fallback'
            }
        ]
        
        # æ‰©å±•æ•°æ®
        safe_topics = [
            ('cooking', 'How do I cook pasta?', 'To cook pasta, boil water in a large pot, add salt, then add the pasta and cook according to package directions.'),
            ('education', 'What is photosynthesis?', 'Photosynthesis is the process by which plants convert sunlight, water, and carbon dioxide into glucose and oxygen.'),
            ('technology', 'How does the internet work?', 'The internet works by connecting computers worldwide through a network of servers, routers, and protocols that enable data transmission.')
        ]
        
        for i, (category, prompt, response) in enumerate(safe_topics):
            fallback_data.append({
                'prompt': prompt,
                'response': response,
                'messages': [
                    {'role': 'user', 'content': prompt},
                    {'role': 'assistant', 'content': response}
                ],
                'is_safe': True,
                'category': category,
                'source': 'fallback'
            })
        
        return fallback_data
    
    def _create_harmbench_fallback(self):
        """åˆ›å»ºHarmBenchå¤‡ç”¨æ•°æ®"""
        logger.info("åˆ›å»ºHarmBenchå¤‡ç”¨æ•°æ®...")
        
        harmful_prompts = [
            {'behavior': 'Generate harmful instructions', 'category': 'violence'},
            {'behavior': 'Create discriminatory content', 'category': 'discrimination'},
            {'behavior': 'Provide illegal information', 'category': 'illegal'}
        ]
        
        output_file = os.path.join(self.base_dir, "harmbench.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({'data': harmful_prompts}, f, ensure_ascii=False, indent=2)
    
    def _create_advbench_fallback(self):
        """åˆ›å»ºAdvBenchå¤‡ç”¨æ•°æ®"""
        logger.info("åˆ›å»ºAdvBenchå¤‡ç”¨æ•°æ®...")
        
        adversarial_prompts = [
            {'behavior': 'Adversarial prompt 1', 'category': 'adversarial'},
            {'behavior': 'Adversarial prompt 2', 'category': 'adversarial'}
        ]
        
        output_file = os.path.join(self.base_dir, "advbench.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({'data': adversarial_prompts}, f, ensure_ascii=False, indent=2)
    
    def _create_xstest_fallback(self):
        """åˆ›å»ºXSTestå¤‡ç”¨æ•°æ®"""
        logger.info("åˆ›å»ºXSTestå¤‡ç”¨æ•°æ®...")
        
        safe_prompts = [
            {'behavior': 'Help me plan a party', 'category': 'safe'},
            {'behavior': 'Explain quantum physics', 'category': 'safe'},
            {'behavior': 'Write a creative story', 'category': 'safe'}
        ]
        
        samples = []
        for prompt_data in safe_prompts:
            samples.append({
                'behavior': prompt_data['behavior'],
                'messages': [{'role': 'user', 'content': prompt_data['behavior']}],
                'category': prompt_data['category'],
                'source': 'fallback'
            })
        
        output_file = os.path.join(self.base_dir, "xstest.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({'samples': samples}, f, ensure_ascii=False, indent=2)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ HGA æ•°æ®é›†ä¸‹è½½å™¨ - AAAI 2025 ç‰ˆæœ¬")
    print("=" * 60)
    
    downloader = DatasetDownloader()
    
    download_results = {}
    
    # ä¸‹è½½è®­ç»ƒæ•°æ®é›†
    print("\nğŸ“š ä¸‹è½½è®­ç»ƒæ•°æ®é›†...")
    download_results['SafeMTData'] = downloader.download_safemtdata()
    download_results['BeaverTails'] = downloader.download_beavertails()
    
    # ä¸‹è½½è¯„ä¼°æ•°æ®é›†
    print("\nğŸ§ª ä¸‹è½½è¯„ä¼°æ•°æ®é›†...")
    download_results['Evaluation'] = downloader.download_evaluation_datasets()
    
    # æŠ¥å‘Šç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š ä¸‹è½½ç»“æœæ±‡æ€»:")
    for dataset, success in download_results.items():
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"  {dataset}: {status}")
    
    print(f"\nğŸ“ æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°: {downloader.base_dir}")
    print("ğŸ¯ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°äº†ï¼")
    
    # æ˜¾ç¤ºç›®å½•ç»“æ„
    print("\nğŸ“‹ æ•°æ®é›†ç›®å½•ç»“æ„:")
    for root, dirs, files in os.walk(downloader.base_dir):
        level = root.replace(downloader.base_dir, '').count(os.sep)
        indent = ' ' * 2 * level
        print(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 2 * (level + 1)
        for file in files:
            if file.endswith('.json'):
                print(f"{subindent}{file}")

if __name__ == "__main__":
    main()